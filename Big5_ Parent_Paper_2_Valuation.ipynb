{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1440 entries, 0 to 1439\n",
      "Data columns (total 55 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Player               1440 non-null   object \n",
      " 1   Nation               1440 non-null   object \n",
      " 2   Pos                  1440 non-null   object \n",
      " 3   Squad                1440 non-null   object \n",
      " 4   Age                  1440 non-null   float64\n",
      " 5   90s                  1440 non-null   float64\n",
      " 6   MP                   1440 non-null   int64  \n",
      " 7   Gls                  1440 non-null   float64\n",
      " 8   Ast                  1440 non-null   float64\n",
      " 9   Sh                   1440 non-null   float64\n",
      " 10  SoT                  1440 non-null   float64\n",
      " 11  xG                   1440 non-null   float64\n",
      " 12  npxG                 1440 non-null   float64\n",
      " 13  xA                   1440 non-null   float64\n",
      " 14  SCA                  1440 non-null   float64\n",
      " 15  GCA                  1440 non-null   float64\n",
      " 16  Cmp                  1440 non-null   float64\n",
      " 17  Att                  1440 non-null   float64\n",
      " 18  Cmp%                 1440 non-null   float64\n",
      " 19  Tkl                  1440 non-null   float64\n",
      " 20  Int                  1440 non-null   float64\n",
      " 21  Clr                  1440 non-null   float64\n",
      " 22  Blocks               1440 non-null   float64\n",
      " 23  Def 3rd              1440 non-null   float64\n",
      " 24  Mid 3rd              1440 non-null   float64\n",
      " 25  Att 3rd              1440 non-null   float64\n",
      " 26  TklW                 1440 non-null   float64\n",
      " 27  Succ_x               1440 non-null   float64\n",
      " 28  KP                   1440 non-null   float64\n",
      " 29  PassLive             1440 non-null   float64\n",
      " 30  PassDead             1440 non-null   float64\n",
      " 31  PrgP                 1440 non-null   float64\n",
      " 32  market_value_in_eur  1440 non-null   float64\n",
      " 33  Touches              1440 non-null   float64\n",
      " 34  Def Pen              1440 non-null   float64\n",
      " 35  Def 3rd_possession   1440 non-null   float64\n",
      " 36  Mid 3rd_possession   1440 non-null   float64\n",
      " 37  Att 3rd_possession   1440 non-null   float64\n",
      " 38  Att Pen              1440 non-null   float64\n",
      " 39  Live_possession      1440 non-null   float64\n",
      " 40  Att_possession       1440 non-null   float64\n",
      " 41  Succ_y               1440 non-null   float64\n",
      " 42  Succ%                1364 non-null   float64\n",
      " 43  Tkld                 1440 non-null   float64\n",
      " 44  Tkld%                1364 non-null   float64\n",
      " 45  Carries              1440 non-null   float64\n",
      " 46  TotDist_possession   1440 non-null   float64\n",
      " 47  PrgDist_possession   1440 non-null   float64\n",
      " 48  PrgC                 1440 non-null   float64\n",
      " 49  1/3_possession       1440 non-null   float64\n",
      " 50  CPA                  1440 non-null   float64\n",
      " 51  Mis                  1440 non-null   float64\n",
      " 52  Dis                  1440 non-null   float64\n",
      " 53  Rec                  1440 non-null   float64\n",
      " 54  PrgR                 1440 non-null   float64\n",
      "dtypes: float64(50), int64(1), object(4)\n",
      "memory usage: 618.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "               Player Nation    Pos           Squad   Age   90s  MP  Gls  Ast  \\\n",
       " 0    Aaron Cresswell    ENG  DF,FW        West Ham  33.0   4.8  11  0.0  0.0   \n",
       " 1  Aaron Wan-Bissaka    ENG     DF  Manchester Utd  25.0  19.8  22  0.0  2.0   \n",
       " 2       Aarón Martín    ESP     DF           Genoa  26.0  15.3  22  0.0  1.0   \n",
       " 3       Abakar Sylla    CIV     DF      Strasbourg  20.0  19.9  22  2.0  0.0   \n",
       " 4        Abdel Abqar    MAR     DF          Alavés  24.0  25.7  27  0.0  0.0   \n",
       " \n",
       "      Sh  ...  Carries  TotDist_possession  PrgDist_possession  PrgC  \\\n",
       " 0   0.0  ...    169.0               522.0               220.0   4.0   \n",
       " 1   3.0  ...    594.0              2909.0              1429.0  30.0   \n",
       " 2   5.0  ...    367.0              1839.0               972.0  28.0   \n",
       " 3  11.0  ...   1060.0              5999.0              3215.0   8.0   \n",
       " 4  10.0  ...    492.0              2460.0              1418.0   7.0   \n",
       " \n",
       "    1/3_possession  CPA   Mis  Dis    Rec  PrgR  \n",
       " 0             5.0  0.0   0.0  2.0  210.0   6.0  \n",
       " 1            27.0  4.0  20.0  9.0  691.0  54.0  \n",
       " 2            21.0  3.0  12.0  4.0  432.0  72.0  \n",
       " 3            11.0  0.0  14.0  7.0  962.0   2.0  \n",
       " 4             6.0  0.0  15.0  1.0  499.0   1.0  \n",
       " \n",
       " [5 rows x 55 columns])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset to examine its structure and prepare for preprocessing\n",
    "data = pd.read_csv('Final.csv')\n",
    "\n",
    "# Display basic info and first few rows to understand the dataset's structure\n",
    "data_info = data.info()\n",
    "data_head = data.head()\n",
    "\n",
    "data_info, data_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dinni\\AppData\\Local\\Temp\\ipykernel_13372\\2803162272.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned['Succ%'].fillna(data_cleaned['Succ%'].median(), inplace=True)\n",
      "C:\\Users\\Dinni\\AppData\\Local\\Temp\\ipykernel_13372\\2803162272.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data_cleaned['Tkld%'].fillna(data_cleaned['Tkld%'].median(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1152, 50), (288, 50), (1152,), (288,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Drop irrelevant columns\n",
    "data_cleaned = data.drop(columns=['Player', 'Nation', 'Pos', 'Squad'])\n",
    "\n",
    "# Handle missing values by filling with median values\n",
    "data_cleaned['Succ%'].fillna(data_cleaned['Succ%'].median(), inplace=True)\n",
    "data_cleaned['Tkld%'].fillna(data_cleaned['Tkld%'].median(), inplace=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data_cleaned.drop(columns=['market_value_in_eur'])\n",
    "y = data_cleaned['market_value_in_eur']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the feature variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the shape of the processed datasets\n",
    "X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 4, 'min_samples_split': 20}\n",
      "Mean Squared Error: 224784100995955.88\n",
      "R-squared: 0.3110472909313584\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import random\n",
    "\n",
    "# Jellyfish Search Optimizer (JSO) Parameters\n",
    "population_size = 20\n",
    "iterations = 50\n",
    "search_space = {\n",
    "    'max_depth': (3, 20),  # Range for max depth of the tree\n",
    "    'min_samples_split': (2, 20)  # Range for min samples split\n",
    "}\n",
    "\n",
    "# Initialize population with random individuals within the search space\n",
    "def initialize_population():\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        individual = {\n",
    "            'max_depth': random.randint(search_space['max_depth'][0], search_space['max_depth'][1]),\n",
    "            'min_samples_split': random.randint(search_space['min_samples_split'][0], search_space['min_samples_split'][1])\n",
    "        }\n",
    "        population.append(individual)\n",
    "    return population\n",
    "\n",
    "# Objective function: Mean Squared Error (MSE)\n",
    "def objective_function(individual):\n",
    "    model = DecisionTreeRegressor(max_depth=individual['max_depth'], min_samples_split=individual['min_samples_split'])\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    return mse\n",
    "\n",
    "# Update individual position based on JSO algorithm rules\n",
    "def update_position(individual, best_individual):\n",
    "    # Random perturbations around the best solution\n",
    "    for param in individual.keys():\n",
    "        if random.random() < 0.5:\n",
    "            # Move towards the best solution\n",
    "            individual[param] = int(best_individual[param] + random.uniform(-1, 1) * (search_space[param][1] - search_space[param][0]) / 2)\n",
    "        else:\n",
    "            # Random movement in the search space\n",
    "            individual[param] = random.randint(search_space[param][0], search_space[param][1])\n",
    "        # Clip the values to ensure they stay within the defined search space\n",
    "        individual[param] = max(search_space[param][0], min(individual[param], search_space[param][1]))\n",
    "    return individual\n",
    "\n",
    "# Main JSO Optimization Loop\n",
    "def jellyfish_search_optimizer():\n",
    "    population = initialize_population()\n",
    "    best_individual = min(population, key=objective_function)  # Best solution based on objective function\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        for i in range(population_size):\n",
    "            # Update each individual towards the best individual found so far\n",
    "            population[i] = update_position(population[i], best_individual)\n",
    "\n",
    "            # Evaluate and update the best individual\n",
    "            if objective_function(population[i]) < objective_function(best_individual):\n",
    "                best_individual = population[i]\n",
    "\n",
    "    return best_individual\n",
    "\n",
    "# Find optimal hyperparameters using JSO\n",
    "best_hyperparameters = jellyfish_search_optimizer()\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "\n",
    "# Train the optimized Decision Tree model\n",
    "optimized_model = DecisionTreeRegressor(max_depth=best_hyperparameters['max_depth'],\n",
    "                                        min_samples_split=best_hyperparameters['min_samples_split'])\n",
    "optimized_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = optimized_model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 4, 'min_samples_split': 16}\n",
      "Mean Squared Error: 222082364139423.12\n",
      "R-squared: 0.3193279874675087\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import random\n",
    "\n",
    "# Honey Badger Algorithm (HBA) Parameters\n",
    "population_size = 20\n",
    "iterations = 50\n",
    "search_space = {\n",
    "    'max_depth': (3, 20),  # Range for max depth of the tree\n",
    "    'min_samples_split': (2, 20)  # Range for min samples split\n",
    "}\n",
    "\n",
    "# Initialize population with random individuals within the search space\n",
    "def initialize_population():\n",
    "    population = []\n",
    "    for _ in range(population_size):\n",
    "        individual = {\n",
    "            'max_depth': random.randint(search_space['max_depth'][0], search_space['max_depth'][1]),\n",
    "            'min_samples_split': random.randint(search_space['min_samples_split'][0], search_space['min_samples_split'][1])\n",
    "        }\n",
    "        population.append(individual)\n",
    "    return population\n",
    "\n",
    "# Objective function: Mean Squared Error (MSE)\n",
    "def objective_function(individual):\n",
    "    model = DecisionTreeRegressor(max_depth=individual['max_depth'], min_samples_split=individual['min_samples_split'])\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    return mse\n",
    "\n",
    "# Update individual position based on HBA algorithm rules\n",
    "def update_position(individual, best_individual, iteration, max_iterations):\n",
    "    for param in individual.keys():\n",
    "        # Honey phase: Move closer to the best solution found\n",
    "        if random.random() < 0.5:\n",
    "            step = (best_individual[param] - individual[param]) * np.exp(-iteration / max_iterations)\n",
    "            individual[param] = int(individual[param] + step)\n",
    "        else:\n",
    "            # Digging phase: Random movement in search space\n",
    "            individual[param] = random.randint(search_space[param][0], search_space[param][1])\n",
    "        \n",
    "        # Clip values to ensure they stay within the defined search space\n",
    "        individual[param] = max(search_space[param][0], min(individual[param], search_space[param][1]))\n",
    "    return individual\n",
    "\n",
    "# Main HBA Optimization Loop\n",
    "def honey_badger_optimizer():\n",
    "    population = initialize_population()\n",
    "    best_individual = min(population, key=objective_function)  # Initial best solution\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        for i in range(population_size):\n",
    "            # Update each individual based on Honey Badger algorithm\n",
    "            population[i] = update_position(population[i], best_individual, iteration, iterations)\n",
    "\n",
    "            # Update best solution if a better one is found\n",
    "            if objective_function(population[i]) < objective_function(best_individual):\n",
    "                best_individual = population[i]\n",
    "\n",
    "    return best_individual\n",
    "\n",
    "# Find optimal hyperparameters using HBA\n",
    "best_hyperparameters = honey_badger_optimizer()\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters)\n",
    "\n",
    "# Train the optimized Decision Tree model\n",
    "optimized_model = DecisionTreeRegressor(max_depth=best_hyperparameters['max_depth'],\n",
    "                                        min_samples_split=best_hyperparameters['min_samples_split'])\n",
    "optimized_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = optimized_model.predict(X_test_scaled)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
